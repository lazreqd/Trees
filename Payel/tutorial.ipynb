{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReforesTree üå¥\n",
    "\n",
    "We are excited to share with you the ReforesTree dataset! üéâ\n",
    "We introduce the ReforesTree dataset in hopes of encouraging the fellow machine learning community to take on\n",
    "the challenge of developing low-cost, scalable, trustworthy and accurate solutions for monitoring, verification and reporting of tropical reforestation inventory. \n",
    "\n",
    "#### This is a dataset for the following 6 agroforestry sites\n",
    "In alphabetical order\n",
    "1. _Carlos Vera Arteaga_\n",
    "2. _Carlos Vera Guevara_\n",
    "3. _Flora Pluas_\n",
    "4. _Leonor Aspiazu_\n",
    "5. _Manuel Macias_\n",
    "6. _Nestor Macias_\n",
    "\n",
    "\n",
    "## Dataset Components\n",
    "For each site the data we publish consists of four components free for use:\n",
    "1. üõ∏ Raw drone RGB images _(see wwf_ecuador/\"Name of site\")_\n",
    "2. üå¥ Hand measured tree parameters (diameter at breast height, species, biomass, and location) of every tree _(see field_data.csv)_\n",
    "3. üî≤ Set of bounding boxes of trees for each site cleaned by hand and labeled as banana or not banana _(see annotations/cleaned)_\n",
    "4. ‚ÜîÔ∏è Mappings of these bounding boxes with tree labels based on location _(see mappings/final)_\n",
    "\n",
    "\n",
    "## Tutorial\n",
    "In this tutorial we go through the steps to recreate (and hopefully improve) the dataset and how to use it. \n",
    "\n",
    "Please read our paper [here](https://arxiv.org/abs/2201.11192).\n",
    "For any questions, please reach out to gyri.reiersen@tum.de or david.dao@inf.eth.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/record/6813783/files/reforesTree.zip?download=1 to data/reforestree/reforesTree.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñç                                                                                    | 42237952/7514326095 [02:58<8:46:31, 236521.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchgeo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReforesTree\n\u001b[0;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mReforesTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/reforestree/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchgeo/datasets/reforestree.py:87\u001b[0m, in \u001b[0;36mReforesTree.__init__\u001b[0;34m(self, root, transforms, download, checksum)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecksum \u001b[38;5;241m=\u001b[39m checksum\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload \u001b[38;5;241m=\u001b[39m download\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchgeo/datasets/reforestree.py:206\u001b[0m, in \u001b[0;36mReforesTree._verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found in `root=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` and `download=False`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither specify a different `root` directory or use `download=True` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto automatically download the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# else download the dataset\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchgeo/datasets/reforestree.py:214\u001b[0m, in \u001b[0;36mReforesTree._download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"Download the dataset and extract it.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m        AssertionError: if the checksum does not match\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzipfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchgeo/datasets/utils.py:166\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    164\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 166\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/datasets/utils.py:144\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 144\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/datasets/utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 48\u001b[0m         \u001b[43m_save_response_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/datasets/utils.py:37\u001b[0m, in \u001b[0;36m_save_response_content\u001b[0;34m(content, destination, length)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_response_content\u001b[39m(\n\u001b[1;32m     32\u001b[0m     content: Iterator[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m     33\u001b[0m     destination: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     34\u001b[0m     length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(destination, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m content:\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     40\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/datasets/utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 48\u001b[0m         _save_response_content(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), filename, length\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchgeo.datasets import ReforesTree\n",
    "ds = ReforesTree(root=\"data/reforestree/\", download=True, checksum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "from PIL import Image\n",
    "import sys\n",
    "package = os.path.dirname(os.getcwd())\n",
    "sys.path.append(package)\n",
    "sys.path.append(package + 'utils')\n",
    "\n",
    "#import seaborn as sns\n",
    "#colors = sns.color_palette('tab10')\n",
    "#mypalette={'NN':colors[0], 'GMN':colors[4], 'OT':colors[1], 'OT on GPS position':colors[1], 'GW':colors[2], 'OT on GPS position + Tree species':colors[3]}\n",
    "#import matplotlib.pylab as plt\n",
    "#import tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extract_features import *\n",
    "from utils.deepforest_detection import *\n",
    "#from utils.visualisation import *\n",
    "#from utils.plot_folium import *\n",
    "#from utils.plot_density import *\n",
    "#from utils.mapping import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ∏ Split raw drone RGB orthomosaics into image tiles\n",
    "1. **Extract drone informations on each site:**\n",
    "Based on the raw data we create the dataframe _ortho_data.csv_ that contains all important information on the drone orthomosaics RGB: minimimal and maximal latititude, longitude, width and height (pixels).\n",
    "\n",
    "\n",
    "2. **Split the orthomosaics into 400x400 tiles:**\n",
    "To be able to handle the drone data we need to split the large .tif files into tiles that is stored in _data/tiles_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"data/wwf_ecuador/RGB Orthomosaics\"\n",
    "save_dir = \"data/tiles\"\n",
    "\n",
    "# Extracting the main information for each site \n",
    "ortho_data = create_ortho_data(directory, os.path.join(save_dir, 'ortho_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split images into tiles (might takes some minutes)\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.tif'):\n",
    "        # Open image file for reading (binary mode)\n",
    "        path_to_raster = os.path.join(directory, file)\n",
    "        name = file.replace('.tif', '')\n",
    "\n",
    "        tiles_dir = os.path.join(save_dir, name)\n",
    "        if not os.path.exists(tiles_dir):\n",
    "            os.makedirs(tiles_dir)        \n",
    "            split_raster(path_to_raster, base_dir=tiles_dir, patch_size=4000, patch_overlap=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üå¥ Rescale drone bounds using field data\n",
    "\n",
    "The \"_field_data.csv_\" contains all the trees on the sites. Each row includes information on the tree parameters as well as the locations and calculated aboveground biomass (AGB) and carbon. \n",
    "\n",
    "PS: It is worth noting that the column \"updated diameter\" is being used for DBH. For completeness and transparancy, the comlumn \"diameter\" is kept and for the trees with missing values (especially cacao) an extrapolated diameter was calculated based on avg. diameter for that species for the year the tree was planted. \n",
    "\n",
    "A separate tutorial on how the processing of the field data is TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>site</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>updated diameter</th>\n",
       "      <th>group</th>\n",
       "      <th>AGB</th>\n",
       "      <th>carbon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181226</td>\n",
       "      <td>-79.576630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>2761.628615</td>\n",
       "      <td>6831.070678</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181312</td>\n",
       "      <td>-79.576412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>5067.141765</td>\n",
       "      <td>7729.961820</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181438</td>\n",
       "      <td>-79.576322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>6025.223497</td>\n",
       "      <td>9026.909643</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181593</td>\n",
       "      <td>-79.576154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>7803.490078</td>\n",
       "      <td>10637.681956</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181498</td>\n",
       "      <td>-79.576179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>7531.400369</td>\n",
       "      <td>9648.963864</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>Musacea</td>\n",
       "      <td>-1.129593</td>\n",
       "      <td>-79.594408</td>\n",
       "      <td>23.236567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>5481.100278</td>\n",
       "      <td>6416.246583</td>\n",
       "      <td>23.236567</td>\n",
       "      <td>banana</td>\n",
       "      <td>24.381901</td>\n",
       "      <td>9.508941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129664</td>\n",
       "      <td>-79.594279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>6767.025955</td>\n",
       "      <td>7172.157045</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>Musacea</td>\n",
       "      <td>-1.129678</td>\n",
       "      <td>-79.594442</td>\n",
       "      <td>21.645022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>5147.097504</td>\n",
       "      <td>7321.370785</td>\n",
       "      <td>21.645022</td>\n",
       "      <td>banana</td>\n",
       "      <td>20.962055</td>\n",
       "      <td>8.175201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129588</td>\n",
       "      <td>-79.594546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>4102.201665</td>\n",
       "      <td>6366.720321</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129495</td>\n",
       "      <td>-79.594575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>3816.384864</td>\n",
       "      <td>5385.084392</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4663 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       lat        lon   diameter  height    year plot_id   \n",
       "0       Cacao -2.181226 -79.576630   0.000000     0.0  2016.0      P8  \\\n",
       "1       Cacao -2.181312 -79.576412   0.000000     0.0  2016.0      P8   \n",
       "2       Cacao -2.181438 -79.576322   0.000000     0.0  2016.0      P8   \n",
       "3       Cacao -2.181593 -79.576154   0.000000     0.0  2016.0      P8   \n",
       "4       Cacao -2.181498 -79.576179   0.000000     0.0  2016.0      P8   \n",
       "...       ...       ...        ...        ...     ...     ...     ...   \n",
       "4658  Musacea -1.129593 -79.594408  23.236567     0.0  2019.0      P7   \n",
       "4659    Cacao -1.129664 -79.594279   0.000000     0.0  2019.0      P7   \n",
       "4660  Musacea -1.129678 -79.594442  21.645022     0.0  2019.0      P7   \n",
       "4661    Cacao -1.129588 -79.594546   0.000000     0.0  2019.0      P7   \n",
       "4662    Cacao -1.129495 -79.594575   0.000000     0.0  2019.0      P7   \n",
       "\n",
       "                   site            X             Y  updated diameter   group   \n",
       "0     Nestor Macias RGB  2761.628615   6831.070678          6.843647   cacao  \\\n",
       "1     Nestor Macias RGB  5067.141765   7729.961820          6.843647   cacao   \n",
       "2     Nestor Macias RGB  6025.223497   9026.909643          6.843647   cacao   \n",
       "3     Nestor Macias RGB  7803.490078  10637.681956          6.843647   cacao   \n",
       "4     Nestor Macias RGB  7531.400369   9648.963864          6.843647   cacao   \n",
       "...                 ...          ...           ...               ...     ...   \n",
       "4658  Manuel Macias RGB  5481.100278   6416.246583         23.236567  banana   \n",
       "4659  Manuel Macias RGB  6767.025955   7172.157045          2.387319   cacao   \n",
       "4660  Manuel Macias RGB  5147.097504   7321.370785         21.645022  banana   \n",
       "4661  Manuel Macias RGB  4102.201665   6366.720321          2.387319   cacao   \n",
       "4662  Manuel Macias RGB  3816.384864   5385.084392          2.387319   cacao   \n",
       "\n",
       "            AGB    carbon  \n",
       "0      5.444228  2.123249  \n",
       "1      5.444228  2.123249  \n",
       "2      5.444228  2.123249  \n",
       "3      5.444228  2.123249  \n",
       "4      5.444228  2.123249  \n",
       "...         ...       ...  \n",
       "4658  24.381901  9.508941  \n",
       "4659   0.676596  0.263872  \n",
       "4660  20.962055  8.175201  \n",
       "4661   0.676596  0.263872  \n",
       "4662   0.676596  0.263872  \n",
       "\n",
       "[4663 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_data = pd.read_csv('data/field_data.csv')\n",
    "field_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then to the actual rescaling\n",
    "list_sites = ['Carlos Vera Arteaga RGB', 'Carlos Vera Guevara RGB', 'Flora Pluas RGB', 'Leonor Aspiazu RGB', \n",
    "             'Manuel Macias RGB', 'Nestor Macias RGB']\n",
    "\n",
    "ortho_data = rescale_bounds(ortho_data, field_data, list_sites)\n",
    "ortho_data.to_csv(os.path.join(save_dir, 'ortho_data.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepforest\n",
    "from deepforest import main\n",
    "from deepforest import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî≤ DeepForest Tree Detection\n",
    "\n",
    "From tiles to bounding box annotations! For that we use a pretrained and finetuned DeepForest model.\n",
    "\n",
    "Note reg finetuning: To make sure our model was able to detect the trees in these sites accurately, we finetuned it on some hand-created bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (294467983.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[83], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = deepforest.deepforest(saved model = os.getcwd()+'/data/model/deepforest/final_model_4000_epochs_35.h5')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "\n",
    "model = deepforest.deepforest(saved model = os.getcwd()+'/data/model/deepforest/final_model_4000_epochs_35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'predict_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m         tile_annotations \u001b[38;5;241m=\u001b[39m \u001b[43mget_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         annotations_files \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([annotations_files, tile_annotations])\n\u001b[1;32m     22\u001b[0m annotations_files \u001b[38;5;241m=\u001b[39m annotations_files\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Dropbox/My Mac (Payels-MacBook-Pro.local)/Downloads/ReforesTree/utils/deepforest_detection.py:62\u001b[0m, in \u001b[0;36mget_annotations\u001b[0;34m(image_path, test_model, score_threshold)\u001b[0m\n\u001b[1;32m     58\u001b[0m tile_annotations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n\u001b[1;32m     60\u001b[0m base \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_path)\n\u001b[0;32m---> 62\u001b[0m annotations \u001b[38;5;241m=\u001b[39m \u001b[43mtest_predict_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(annotations) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m annotations\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/Dropbox/My Mac (Payels-MacBook-Pro.local)/Downloads/ReforesTree/utils/deepforest_detection.py:35\u001b[0m, in \u001b[0;36mtest_predict_boxes\u001b[0;34m(image_path, test_model, score_threshold)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mReturns the tree detections by DeepForest model.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict test image and return boxes\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m boxes \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_image\u001b[49m(image_path\u001b[38;5;241m=\u001b[39mget_data(image_path),\n\u001b[1;32m     36\u001b[0m                                  show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m                                  return_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m                                  score_threshold\u001b[38;5;241m=\u001b[39mscore_threshold)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Returns a 6 column numpy array, xmin, ymin, xmax, ymax, score, label\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'predict_image'"
     ]
    }
   ],
   "source": [
    "# Detect trees per tile and return bounding box annotations for each site\n",
    "column_names = ['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'score']\n",
    "\n",
    "dir = os.path.join(os.getcwd(), 'data')\n",
    "tiles_dir = os.path.join(dir,'tiles')\n",
    "ann_dir = os.path.join(dir,'annotations')\n",
    "\n",
    "if not os.path.exists(ann_dir):\n",
    "    os.makedirs(ann_dir)\n",
    "\n",
    "for folder in os.listdir(tiles_dir):\n",
    "    if not (folder.startswith('.') or folder.startswith('ortho_data.csv')):\n",
    "        file_path = ann_dir + '/{}_annotations.csv'.format(folder)\n",
    "        if not os.path.exists(file_path):\n",
    "            annotations_files = pd.DataFrame(columns = column_names)\n",
    "            folder_path = os.path.join(tiles_dir,folder)\n",
    "            \n",
    "            for file in os.listdir(folder_path):\n",
    "                if not file.startswith('.'):\n",
    "                    tile_annotations = get_annotations(os.path.join(folder_path, file), model)\n",
    "                    annotations_files = pd.concat([annotations_files, tile_annotations])\n",
    "            annotations_files = annotations_files.reset_index(drop=True)\n",
    "\n",
    "            annotations_files.to_csv(file_path, index=False)\n",
    "        print('DeepForest annotations are saved for site {}'.format(folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional tile information per bounding box annotation\n",
    "\n",
    "For each tree annotation we add tree location, tile position, and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for site_name in list_sites:\n",
    "    for file in os.listdir(ann_dir):\n",
    "        if (file == '{}_annotations.csv'.format(site_name)):\n",
    "            file_path = os.path.join(ann_dir,file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if not ('Xmin' in df.columns): # in case you have done this before\n",
    "                df['img_name'], df['tile_index'], df['tile_xmin'], df['tile_ymin'], df['tile_xmax'], df['tile_ymax'] = zip(*df['img_path'].map(expand_tile_features))\n",
    "                df[['x', 'y']] = df.apply(lambda x: [get_center(x.xmin,x.xmax), get_center(x.ymin,x.ymax)], axis=1, result_type=\"expand\")\n",
    "\n",
    "                df['Xmin'] = df.xmin + df.tile_xmin\n",
    "                df['Ymin'] = df.ymin + df.tile_ymin\n",
    "                df['Xmax'] = df.xmax + df.tile_xmin\n",
    "                df['Ymax'] = df.ymax + df.tile_ymin\n",
    "                df['X'] = df.x + df.tile_xmin\n",
    "                df['Y'] = df.y + df.tile_ymin\n",
    "\n",
    "                df[['lon', 'lat']] = df.apply(lambda x: convert_xy_tile_to_lonlat(x.img_name, x.tile_xmin, x.tile_ymin, x.x, x.y, ortho_data), axis=1, result_type=\"expand\")\n",
    "                df.to_csv(file_path, index = False)\n",
    "            print('Added info for {}'.format(site_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge annotations files of each site into one file\n",
    "all_annotations = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(ann_dir):\n",
    "    if not (file.startswith('.') or file.startswith('c') or file.startswith('a')):\n",
    "        file_path = os.path.join(ann_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_annotations = pd.concat([all_annotations, df])\n",
    "all_annotations.to_csv(os.path.join(ann_dir,'all_annotations.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üçå Cleaned bounding boxes\n",
    "As part of our work, we have manually cleaned the bounding boxes coming out of deepforest. This was done in two parts; one filtering out bboxes that were not of trees, due to size (e.g. too large area or only of a leaf) or due to wrong detection (of a car or grass). The second part consisted of labelling the trees as either \"banana\" (easily recognizable looking like a palm tree) or \"other\". \n",
    "\n",
    "Please find the cleaned dataset in \"_data/annotations/cleaned_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'score', 'img_name',\n",
       "       'tile_index', 'tile_xmin', 'tile_ymin', 'tile_xmax', 'tile_ymax', 'x',\n",
       "       'y', 'Xmin', 'Ymin', 'Xmax', 'Ymax', 'X', 'Y', 'lon', 'lat',\n",
       "       'is_banana'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_annotations = pd.read_csv('data/annotations/cleaned/clean_annotations.csv')\n",
    "clean_annotations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ÜîÔ∏è Matching of tree label + bounding box\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
